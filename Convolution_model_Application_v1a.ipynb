{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks: Application\n",
    "\n",
    "Welcome to Course 4's second assignment! In this notebook, you will:\n",
    "\n",
    "- Implement helper functions that you will use when implementing a TensorFlow model\n",
    "- Implement a fully functioning ConvNet using TensorFlow \n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Build and train a ConvNet in TensorFlow for a classification problem \n",
    "\n",
    "We assume here that you are already familiar with TensorFlow. If you are not, please refer the *TensorFlow Tutorial* of the third week of Course 2 (\"*Improving deep neural networks*\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'> Updates to Assignment <font>\n",
    "\n",
    "#### If you were working on a previous version\n",
    "* The current notebook filename is version \"1a\". \n",
    "* You can find your work in the file directory as version \"1\".\n",
    "* To view the file directory, go to the menu \"File->Open\", and this will open a new tab that shows the file directory.\n",
    "\n",
    "#### List of Updates\n",
    "* `initialize_parameters`: added details about tf.get_variable, `eval`. Clarified test case.\n",
    "* Added explanations for the kernel (filter) stride values, max pooling, and flatten functions.\n",
    "* Added details about softmax cross entropy with logits.\n",
    "* Added instructions for creating the Adam Optimizer.\n",
    "* Added explanation of how to evaluate tensors (optimizer and cost).\n",
    "* `forward_propagation`: clarified instructions, use \"F\" to store \"flatten\" layer.\n",
    "* Updated print statements and 'expected output' for easier visual comparisons.\n",
    "* Many thanks to Kevin P. Brown (mentor for the deep learning specialization) for his suggestions on the assignments in this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 - TensorFlow model\n",
    "\n",
    "In the previous assignment, you built helper functions using numpy to understand the mechanics behind convolutional neural networks. Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. \n",
    "\n",
    "As usual, we will start by loading in the packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to load the \"SIGNS\" dataset you are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.\n",
    "\n",
    "<img src=\"images/SIGNS.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of `index` below and re-run to see different examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47d002ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 25\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Course 2, you had built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.\n",
    "\n",
    "To get started, let's examine the shapes of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Create placeholders\n",
    "\n",
    "TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.\n",
    "\n",
    "**Exercise**: Implement the function below to create placeholders for the input image X and the output Y. You should not define the number of training examples for the moment. To do so, you could use \"None\" as the batch size, it will give you the flexibility to choose it later. Hence X should be of dimension **[None, n_H0, n_W0, n_C0]** and Y should be of dimension **[None, n_y]**.  [Hint: search for the tf.placeholder documentation\"](https://www.tensorflow.org/api_docs/python/tf/placeholder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape=(None,n_H0, n_W0, n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(64, 64, 3, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "<td>\n",
    "    X = Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    Y = Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Initialize parameters\n",
    "\n",
    "You will initialize weights/filters $W1$ and $W2$ using `tf.contrib.layers.xavier_initializer(seed = 0)`. You don't need to worry about bias variables as you will soon see that TensorFlow functions take care of the bias. Note also that you will only initialize the weights/filters for the conv2d functions. TensorFlow initializes the layers for the fully connected part automatically. We will talk more about that later in this assignment.\n",
    "\n",
    "**Exercise:** Implement initialize_parameters(). The dimensions for each group of filters are provided below. Reminder - to initialize a parameter $W$ of shape [1,2,3,4] in Tensorflow, use:\n",
    "```python\n",
    "W = tf.get_variable(\"W\", [1,2,3,4], initializer = ...)\n",
    "```\n",
    "#### tf.get_variable()\n",
    "[Search for the tf.get_variable documentation](https://www.tensorflow.org/api_docs/python/tf/get_variable).  Notice that the documentation says:\n",
    "```\n",
    "Gets an existing variable with these parameters or create a new one.\n",
    "```\n",
    "So we can use this function to create a tensorflow variable with the specified name, but if the variables already exist, it will get the existing variable with that same name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Note that we will hard code the shape values in the function to make the grading simpler.\n",
    "    Normally, functions should take values as inputs rather than hard coding.\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable('W1', [4,4,3,8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable('W2', [2,2,8,16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1[1,1,1] = \n",
      "[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394\n",
      " -0.06847463  0.05245192]\n",
      "W1.shape: (4, 4, 3, 8)\n",
      "\n",
      "\n",
      "W2[1,1,1] = \n",
      "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
      " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
      " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n",
      "W2.shape: (2, 2, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1[1,1,1] = \\n\" + str(parameters[\"W1\"].eval()[1,1,1]))\n",
    "    print(\"W1.shape: \" + str(parameters[\"W1\"].shape))\n",
    "    print(\"\\n\")\n",
    "    print(\"W2[1,1,1] = \\n\" + str(parameters[\"W2\"].eval()[1,1,1]))\n",
    "    print(\"W2.shape: \" + str(parameters[\"W2\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output:**\n",
    "\n",
    "```\n",
    "W1[1,1,1] = \n",
    "[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394\n",
    " -0.06847463  0.05245192]\n",
    "W1.shape: (4, 4, 3, 8)\n",
    "\n",
    "\n",
    "W2[1,1,1] = \n",
    "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
    " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
    " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n",
    "W2.shape: (2, 2, 8, 16)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Forward propagation\n",
    "\n",
    "In TensorFlow, there are built-in functions that implement the convolution steps for you.\n",
    "\n",
    "- **tf.nn.conv2d(X,W, strides = [1,s,s,1], padding = 'SAME'):** given an input $X$ and a group of filters $W$, this function convolves $W$'s filters on X. The third parameter ([1,s,s,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). Normally, you'll choose a stride of 1 for the number of examples (the first value) and for the channels (the fourth value), which is why we wrote the value as `[1,s,s,1]`. You can read the full documentation on [conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d).\n",
    "\n",
    "- **tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME'):** given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window.  For max pooling, we usually operate on a single example at a time and a single channel at a time.  So the first and fourth value in `[1,f,f,1]` are both 1.  You can read the full documentation on [max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool).\n",
    "\n",
    "- **tf.nn.relu(Z):** computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu).\n",
    "\n",
    "- **tf.contrib.layers.flatten(P)**: given a tensor \"P\", this function takes each training (or test) example in the batch and flattens it into a 1D vector.  \n",
    "    * If a tensor P has the shape (m,h,w,c), where m is the number of examples (the batch size), it returns a flattened tensor with shape (batch_size, k), where $k=h \\times w \\times c$.  \"k\" equals the product of all the dimension sizes other than the first dimension.\n",
    "    * For example, given a tensor with dimensions [100,2,3,4], it flattens the tensor to be of shape [100, 24], where 24 = 2 * 3 * 4.  You can read the full documentation on [flatten](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten).\n",
    "\n",
    "- **tf.contrib.layers.fully_connected(F, num_outputs):** given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on [full_connected](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected).\n",
    "\n",
    "In the last function above (`tf.contrib.layers.fully_connected`), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.\n",
    "\n",
    "\n",
    "#### Window, kernel, filter\n",
    "The words \"window\", \"kernel\", and \"filter\" are used to refer to the same thing.  This is why the parameter `ksize` refers to \"kernel size\", and we use `(f,f)` to refer to the filter size.  Both \"kernel\" and \"filter\" refer to the \"window.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Implement the `forward_propagation` function below to build the following model: `CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED`. You should use the functions above. \n",
    "\n",
    "In detail, we will use the following parameters for all the steps:\n",
    " - Conv2D: stride 1, padding is \"SAME\"\n",
    " - ReLU\n",
    " - Max pool: Use an 8 by 8 filter size and an 8 by 8 stride, padding is \"SAME\"\n",
    " - Conv2D: stride 1, padding is \"SAME\"\n",
    " - ReLU\n",
    " - Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is \"SAME\"\n",
    " - Flatten the previous output.\n",
    " - FULLYCONNECTED (FC) layer: Apply a fully connected layer without an non-linear activation function. Do not call the softmax here. This will result in 6 neurons in the output layer, which then get passed later to a softmax. In TensorFlow, the softmax and cost function are lumped together into a single function, which you'll call in a different function when computing the cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Note that for simplicity and grading purposes, we'll hard-code some values\n",
    "    such as the stride and kernel (filter) sizes. \n",
    "    Normally, functions should take these values as function parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1,  strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize=[1,8,8,1], strides=[1,8,8,1], padding='SAME') # ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME'\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize=[1,4,4,1], strides=[1,4,4,1], padding='SAME')\n",
    "    # FLATTEN\n",
    "    F = tf.contrib.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(F,6,activation_fn=None)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = \n",
      "[[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]\n",
      " [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(64, 64, 3, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,6)})\n",
    "    print(\"Z3 = \\n\" + str(a))\n",
    "#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=Z3))\n",
    "#     b = sess.run(cost, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,6)})\n",
    "#     print(\"cost = \\n\" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "```\n",
    "Z3 = \n",
    "[[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]\n",
    " [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Compute cost\n",
    "\n",
    "Implement the compute cost function below. Remember that the cost function helps the neural network see how much the model's predictions differ from the correct labels.  By adjusting the weights of the network to reduce the cost, the neural network can improve its predictions.\n",
    "\n",
    "You might find these two functions helpful: \n",
    "\n",
    "- **tf.nn.softmax_cross_entropy_with_logits(logits = Z, labels = Y):** computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation  [softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits).\n",
    "- **tf.reduce_mean:** computes the mean of elements across dimensions of a tensor. Use this to calculate the sum of the losses over all the examples to get the overall cost. You can check the full documentation [reduce_mean](https://www.tensorflow.org/api_docs/python/tf/reduce_mean).\n",
    "\n",
    "#### Details on softmax_cross_entropy_with_logits (optional reading)\n",
    "* Softmax is used to format outputs so that they can be used for classification.  It assigns a value between 0 and 1 for each category, where the sum of all prediction values (across all possible categories) equals 1.\n",
    "* Cross Entropy is compares the model's predicted classifications with the actual labels and results in a numerical value representing the \"loss\" of the model's predictions.\n",
    "* \"Logits\" are the result of multiplying the weights and adding the biases.  Logits are passed through an activation function (such as a relu), and the result is called the \"activation.\"\n",
    "* The function is named `softmax_cross_entropy_with_logits` takes logits as input (and not activations); then uses the model to predict using softmax, and then compares the predictions with the true labels using cross entropy.  These are done with a single function to optimize the calculations.\n",
    "\n",
    "** Exercise**: Compute the cost below using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=Z3))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 2.91034\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(64, 64, 3, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: np.random.randn(4,64,64,3), Y: np.random.randn(4,6)})\n",
    "    print(\"cost = \" + str(a))\n",
    "    #a = sess.run(Z3, {X: np.random.randn(4,64,64,3), Y: np.random.randn(4,6)})\n",
    "    #print(\"Z3 = \\n\" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "```\n",
    "cost = 2.91034\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Model \n",
    "\n",
    "Finally you will merge the helper functions you implemented above to build a model. You will train it on the SIGNS dataset. \n",
    "\n",
    "**Exercise**: Complete the function below. \n",
    "\n",
    "The model below should:\n",
    "\n",
    "- create placeholders\n",
    "- initialize parameters\n",
    "- forward propagate\n",
    "- compute the cost\n",
    "- create an optimizer\n",
    "\n",
    "Finally you will create a session and run a for loop  for num_epochs, get the mini-batches, and then for each mini-batch you will optimize the function. [Hint for initializing the variables](https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam Optimizer\n",
    "You can use `tf.train.AdamOptimizer(learning_rate = ...)` to create the optimizer.  The optimizer has a `minimize(loss=...)` function that you'll call to set the cost function that the optimizer will minimize.\n",
    "\n",
    "For details, check out the documentation for [Adam Optimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random mini batches\n",
    "If you took course 2 of the deep learning specialization, you implemented `random_mini_batches()` in the \"Optimization\" programming assignment. This function returns a list of mini-batches. It is already implemented in the `cnn_utils.py` file and imported here, so you can call it like this:\n",
    "```Python\n",
    "minibatches = random_mini_batches(X, Y, mini_batch_size = 64, seed = 0)\n",
    "```\n",
    "(You will want to choose the correct variable names when you use it in your code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the optimizer and cost\n",
    "\n",
    "Within a loop, for each mini-batch, you'll use the `tf.Session` object (named `sess`) to feed a mini-batch of inputs and labels into the neural network and evaluate the tensors for the optimizer as well as the cost.  Remember that we built a graph data structure and need to feed it inputs and labels and use `sess.run()` in order to get values for the optimizer and cost.\n",
    "\n",
    "You'll use this kind of syntax:\n",
    "```\n",
    "output_for_var1, output_for_var2 = sess.run(\n",
    "                                                fetches=[var1, var2],\n",
    "                                                feed_dict={var_inputs: the_batch_of_inputs,\n",
    "                                                           var_labels: the_batch_of_labels}\n",
    "                                                )\n",
    "```\n",
    "* Notice that `sess.run` takes its first argument `fetches` as a list of objects that you want it to evaluate (in this case, we want to evaluate the optimizer and the cost).  \n",
    "* It also takes a dictionary for the `feed_dict` parameter.  \n",
    "* The keys are the `tf.placeholder` variables that we created in the `create_placeholders` function above.  \n",
    "* The values are the variables holding the actual numpy arrays for each mini-batch.  \n",
    "* The sess.run outputs a tuple of the evaluated tensors, in the same order as the list given to `fetches`. \n",
    "\n",
    "For more information on how to use sess.run, see the documentation [tf.Sesssion#run](https://www.tensorflow.org/api_docs/python/tf/Session#run) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=cost) #optimizer.minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                print(minibatch_X.shape, minibatch_Y.shape)\n",
    "                \n",
    "                \"\"\"\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost.\n",
    "                # The feedict should contain a minibatch for (X,Y).\n",
    "                \"\"\"\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run(fetches=[optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your model for 100 epochs. Check if your cost after epoch 0 and 5 matches our output. If not, stop the cell and go back to your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 0: 1.917929\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 5: 1.506757\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 10: 0.955359\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 15: 0.845802\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 20: 0.701174\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 25: 0.571977\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 30: 0.518435\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 35: 0.495806\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 40: 0.429827\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 45: 0.407291\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 50: 0.366394\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 55: 0.376922\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 60: 0.299491\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 65: 0.338870\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 70: 0.316400\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 75: 0.310413\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 80: 0.249549\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 85: 0.243457\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 90: 0.200031\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "Cost after epoch 95: 0.175452\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(64, 64, 64, 3) (64, 6)\n",
      "(56, 64, 64, 3) (56, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPypHYdmk//r2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f477d338ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.940741\n",
      "Test Accuracy: 0.783333\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: although it may not match perfectly, your expected output should be close to ours and your cost value should decrease.\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "    <td> \n",
    "    **Cost after epoch 0 =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      1.917929\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    **Cost after epoch 5 =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      1.506757\n",
    "    </td> \n",
    "</tr>\n",
    "<tr>\n",
    "    <td> \n",
    "    **Train Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.940741\n",
    "    </td> \n",
    "</tr> \n",
    "\n",
    "<tr>\n",
    "    <td> \n",
    "    **Test Accuracy   =**\n",
    "    </td>\n",
    "\n",
    "    <td> \n",
    "      0.783333\n",
    "    </td> \n",
    "</tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have finished the assignment and built a model that recognizes SIGN language with almost 80% accuracy on the test set. If you wish, feel free to play around with this dataset further. You can actually improve its accuracy by spending more time tuning the hyperparameters, or using regularization (as this model clearly has a high variance). \n",
    "\n",
    "Once again, here's a thumbs up for your work! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"images/thumbs_up.jpg\"\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(64,64))\n",
    "plt.imshow(my_image)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "bwbJV",
   "launcher_item_id": "0TkXB"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
