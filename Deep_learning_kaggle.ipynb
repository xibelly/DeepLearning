{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning - Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "hot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/hot_dog'\n",
    "\n",
    "hot_dog_paths = [join(hot_dog_image_dir,filename) for filename in \n",
    "                            ['1000288.jpg',\n",
    "                             '127117.jpg']]\n",
    "\n",
    "not_hot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/not_hot_dog'\n",
    "not_hot_dog_paths = [join(not_hot_dog_image_dir, filename) for filename in\n",
    "                            ['823536.jpg',\n",
    "                             '99890.jpg']]\n",
    "\n",
    "img_paths = hot_dog_paths + not_hot_dog_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from IPython.display import Image, display\n",
    "from learntools.deep_learning.decode_predictions import decode_predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data \n",
    "image_size = 224\n",
    "\n",
    "#This function receive the image path and the image size and use the function \"load_img\" and \"img_to_array\" to preprocess the data\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model \n",
    "\n",
    "# The model that will be used is ResNet model\n",
    "# ResNet : model used to train extremely deep neural networks \n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5') #pre-defined weights\n",
    "test_data = read_and_prep_images(img_paths)\n",
    "preds = my_model.predict(test_data)\n",
    "\n",
    "most_likely_labels = decode_predictions(preds, top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    display(Image(img_path))\n",
    "    print(most_likely_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_3 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We want to distinguish whether an image is a hot dog or not. But our models classify pictures into 1000 different categories. Write a function that takes the models predictions (in the same format as `preds` from the set-up code) and returns a list of `True` and `False` values.\n",
    "\n",
    "Some tips:\n",
    "- Work iteratively. Figure out one line at a time outsie the function, and print that line's output to make sure it's right. Once you have all the code you need, move it into the function `is_hot_dog`. If you get an error, check that you have copied the right code and haven't left anything out.\n",
    "- The raw data we loaded in `img_paths` had two images of hot dogs, followed by two images of other foods. So, if you run your function on `preds`, which represents the output of the model on these images, your function should return `[True, True, False, False]`.\n",
    "- You will want to use the `decode_predictions` function that was also used in the code provided above. We provided a line with this in the code cell to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with code outside the function, then move it into the function once you think it is right\n",
    "\n",
    "# the following lines are given as a hint to get you started\n",
    "decoded = decode_predictions(preds, top=1)\n",
    "print(decoded)\n",
    "import re\n",
    "\n",
    "def is_hot_dog(preds):\n",
    "    '''\n",
    "    inputs:\n",
    "    preds_array:  array of predictions from pre-trained model\n",
    "    \n",
    "    outputs:\n",
    "    is_hot_dog_list: a list indicating which predictions show hotdog as the most likely label\n",
    "    '''\n",
    "    \n",
    "    preds_array = decode_predictions(preds, top=1)\n",
    "    is_hot_dog_list = []\n",
    "    for pred in preds_array:\n",
    "        for item in pred:\n",
    "            x = re.search(\"hotdog\",item[1])\n",
    "            if(x): \n",
    "                result =True\n",
    "            else:\n",
    "                result = False\n",
    "            \n",
    "            is_hot_dog_list.append(result)     \n",
    "            \n",
    "        pass \n",
    "    return is_hot_dog_list\n",
    "    \n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Evaluate Model Accuracy\n",
    "\n",
    "You have a model (called 'y_model'. Is it good enough to build your app around? \n",
    "\n",
    "Find out by writing a function that calculates a model's accuracy (fraction correct). You will try an alternative model in the next step. So we will put this logic in a reusable function that takes data and the model as arguments, and returns the accuracy.\n",
    "\n",
    "Tips:\n",
    "\n",
    " - Use the `is_hot_dog` function from above to help write your function\n",
    " - To save you some scrolling, here is the code from above where we used a TensorFlow model to make predictions:\n",
    "\n",
    "'''\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "test_data = read_and_prep_images(img_paths)\n",
    "preds = my_model.predict(test_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(model, paths_to_hotdog_images, paths_to_other_images):\n",
    "    \n",
    "    #Preparing the images\n",
    "    data1 = read_and_prep_images(paths_to_hotdog_images)\n",
    "    data2 = read_and_prep_images(paths_to_other_images)\n",
    "    \n",
    "    #Make the predictions with the defined model\n",
    "    pred_d1 = model.predict(data1)\n",
    "    \n",
    "    pred_d2 = model.predict(data2)\n",
    "    \n",
    "    #Analizing if a image is or not a hotdog\n",
    "    list_d1 = is_hot_dog(pred_d1)\n",
    "    \n",
    "    list_d2 = is_hot_dog(pred_d2)\n",
    "    \n",
    "    #Computing the accuracy as the fraction between list_d1 and list_d2\n",
    "    \n",
    "    size = len(pred_d1)*len(pred_d2)\n",
    "    r = 0\n",
    "    for d1 in pred_d1:\n",
    "        for d2 in pred_d2:\n",
    "            r +=  d1.any() / d2.any()\n",
    "        pass  \n",
    "    \n",
    "    accu = r / size\n",
    "    return(accu)\n",
    "\n",
    "# Code to call calc_accuracy.  my_model, hot_dog_paths and not_hot_dog_paths were created in the setup code\n",
    "my_model_accuracy = calc_accuracy(my_model, hot_dog_paths, not_hot_dog_paths)\n",
    "print(\"Fraction correct in small test set: {}\".format(my_model_accuracy))\n",
    "\n",
    "# checks that your function calc_accuracy works correctly\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "There are other models besides the ResNet model (which we have loaded). For example, an earlier winner of the ImageNet competition is the VGG16 model.  Don't worry about the differences between these models yet. We'll come back to that later. For now, just focus on the mechanics of applying these models to a problem.\n",
    "\n",
    "The code used to load a pretrained ResNet50 model was\n",
    "\n",
    "```\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "```\n",
    "\n",
    "The weights for the model are stored at `../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5`.\n",
    "\n",
    "In the cell below, create a VGG16 model with the preloaded weights. Then use your `calc_accuracy` function to determine what fraction of images the VGG16 model correctly classifies.  Is it better or worse than the pretrained ResNet model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "\n",
    "vgg16_model = VGG16(weights='../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "# calculate accuracy on small dataset as a test\n",
    "vgg16_accuracy = calc_accuracy(vgg16_model, hot_dog_paths, not_hot_dog_paths)\n",
    "\n",
    "\n",
    "print(\"Fraction correct in small dataset: {}\".format(vgg16_accuracy))\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "You don't directly choose the numbers to go into your convolutions for deep learning... instead the deep learning technique determines what convolutions will be useful from the data (as part of model-training). We'll come back to how the model does that soon.\n",
    "\n",
    "![Imgur](https://i.imgur.com/op9Maqr.png)\n",
    "\n",
    "But looking closely at convolutions and how they are applied to your image will improve your intuition for these models, how they work, and how to debug them when they don't work.\n",
    "\n",
    "**Let's get started.**\n",
    "\n",
    "# Exercises\n",
    "We'll use some small utilty functions to visualize raw images and some results of your code. Execute the next cell to load the utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'learntools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ee34a53c3820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set up code checking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlearntools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbinder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlearntools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeep_learning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexercise_1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Setup Complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'learntools'"
     ]
    }
   ],
   "source": [
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_1 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "In the video, you saw a convolution that detected horizontal lines. That convolution shows up again in the code cell below.\n",
    "\n",
    "Run the cell to see a raw image as well as the output from applying this convolution to the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_line_conv = [[1, 1], \n",
    "                        [-1, -1]]\n",
    "# load_my_image and visualize_conv are utility functions provided for this exercise\n",
    "original_image = load_my_image() \n",
    "visualize_conv(original_image, horizontal_line_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn. Instead of a horizontal line detector, you will create a vertical line detector.\n",
    "\n",
    "**Replace the underscores with numbers to make a vertical line detector and uncomment both lines of code in the cell below. Then run **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_line_conv = [[-1,1],[-1,1]]\n",
    "\n",
    "q_1.check()\n",
    "visualize_conv(original_image, vertical_line_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "The convolutions you've seen are 2x2.  But you could have larger convolutions. They could be 3x3, 4x4, etc.  They don't even have to be square. Nothing prevents using a 4x7 convolution.\n",
    "\n",
    "Compare the number of visual patterns that can be captured by small convolutions. Which of the following is true?\n",
    "\n",
    "- There are more visual patterns that can be captured by large convolutions\n",
    "- There are fewer visual patterns that can be captured by large convolutions\n",
    "- The number of visual patterns that can be captured by large convolutions is the same as the number of visual patterns that can be captured by small convolutions?\n",
    "\n",
    "Once you think you know the answer, check it by uncommenting and running the line below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer - learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Introduction\n",
    "\n",
    "The cameraman who shot our deep learning videos mentioned a problem that we can solve with deep learning.  \n",
    "\n",
    "He offers a service that scans photographs to store them digitally.  He uses a machine that quickly scans many photos. But depending on the orientation of the original photo, many images are digitized sideways.  He fixes these manually, looking at each photo to determine which ones to rotate.\n",
    "\n",
    "In this exercise, you will build a model that distinguishes which photos are sideways and which are upright, so an app could automatically rotate each image if necessary.\n",
    "\n",
    "If you were going to sell this service commercially, you might use a large dataset to train the model. But you'll have great success with even a small dataset.  You'll work with a small dataset of dog pictures, half of which are rotated sideways.\n",
    "\n",
    "Specifying and compiling the model look the same as in the example you've seen. But you'll need to make some changes to fit the model.\n",
    "\n",
    "**Run the following cell to set up automatic feedback.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_4 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Specify the Model\n",
    "\n",
    "Since this is your first time, we'll provide some starter code for you to modify. You will probably copy and modify code the first few times you work on your own projects.\n",
    "\n",
    "There are some important parts left blank in the following code.\n",
    "\n",
    "Fill in the blanks (marked with `____`) and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "num_classes = 2\n",
    "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Indicate whether the first layer should be trained/changed or not.\n",
    "my_new_model.layers[0].trainable = False\n",
    "\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compile the Model\n",
    "\n",
    "You now compile the model with the following line.  Run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.compile(optimizer='sgd', \n",
    "                     loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Review the Compile Step\n",
    "You provided three arguments in the compile step.  \n",
    "- optimizer\n",
    "- loss\n",
    "- metrics\n",
    "\n",
    "Which arguments could affect the accuracy of the predictions that come out of the model?  After you have your answer, run the cell below to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution:\n",
    "\n",
    "- optimizer determines how we determine the numerical values that make up the model. So it can affect the resulting model and predictions\n",
    "- loss determines what goal we optimize when determining numerical values in the model. So it can affect the resulting model and predictions\n",
    "- metrics determines only what we print out while the model is being built, but it doesn't affect the model itself.\n",
    "\n",
    "You may not understand all of this yet. That's totally fine for now. It will become clearer in an upcoming lesson (called A Deeper Understanding of Deep Learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Fit Model\n",
    "\n",
    "**Your training data is in the directory `../input/dogs-gone-sideways/images/train`. The validation data is in `../input/dogs-gone-sideways/images/val`**. Use that information when setting up `train_generator` and `validation_generator`.\n",
    "\n",
    "You have 220 images of training data and 217 of validation data.  For the training generator, we set a batch size of 10. Figure out the appropriate value of `steps_per_epoch` in your `fit_generator` call. #ES DE 22!!! YA QUE 220 imgs en contenedores de 10 nos lleva a 22 steps\n",
    "\n",
    "Fill in all the blanks (again marked as `____`).  Then run the cell of code.  Watch as your model trains the weights and the accuracy improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "data_generator = ImageDataGenerator(preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "                                        directory='../input/dogs-gone-sideways/images/train',\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=10,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "                                        directory='../input/dogs-gone-sideways/images/val',\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "# fit_stats below saves some statistics describing how model fitting went\n",
    "# the key role of the following line is how it changes my_new_model by fitting to data\n",
    "fit_stats = my_new_model.fit_generator(train_generator,\n",
    "                                       steps_per_epoch=22,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       validation_steps=1)\n",
    "\n",
    "step_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Introduction\n",
    "We will return to the automatic rotation problem you worked on in the previous exercise. But we'll add data augmentation to improve your model.\n",
    "\n",
    "The model specification and compilation steps don't change when you start using data augmentation. The code you've already worked with for specifying and compiling a model is in the cell below.  Run it so you'll be ready to work on data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "num_classes = 2\n",
    "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "my_new_model.layers[0].trainable = False\n",
    "\n",
    "my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_5 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Fit the Model Using Data Augmentation\n",
    "\n",
    "Here is some code to set up some ImageDataGenerators. Run it, and then answer the questions below about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "# Specify the values for all arguments to data_generator_with_aug.\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.1,\n",
    "                                              height_shift_range = 0.1)\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need both a generator with augmentation and a generator without augmentation? After thinking about it, check out the solution below.\n",
    "\n",
    "Solution: We want to do data augmentation when fitting the model for the reasons mentioned in the video (including a reduction in overfitting, by giving us more data to work with).\n",
    "\n",
    "But we don't want to change how we test the model. So the validation generator will use an ImageDataGenerator without augmentation. That allows a straightforward comparison between different training procedures (e.g. training with augmentation and without it).\n",
    "\n",
    "If the augmentation made it harder to predict the label associated with an image (e.g. because of how the image was cropped in augmentation) that would make it misleading to compare scores to another procedure where the validation data was only original images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Choosing Augmentation Types\n",
    "ImageDataGenerator offers many types of data augmentation. For example, one argument is `rotation_range`. This rotates each image by a random amount that can be up to whatever value you specify.\n",
    "\n",
    "Would it be sensible to use automatic rotation for this problem?  Why or why not?\n",
    "\n",
    "Solution: The goal in this problem is to tell if an image is upright or sideways. Rotating images moderately might cause images that don't feel cleanly in either category.\n",
    "\n",
    "Since data augmentation affects images without touching the labels, a dramatic rotation would mean some images are used for training with the wrong label (e.g. an image would be rotated sideways by the generator, and still have a label of being upright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Code\n",
    "Fill in the missing pieces in the following code. We've supplied some boilerplate. You need to think about what ImageDataGenerator is used for each data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify which type of ImageDataGenerator above is to load in training data\n",
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "        directory = '../input/dogs-gone-sideways/images/train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=12,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Specify which type of ImageDataGenerator above is to load in validation data\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "        directory = '../input/dogs-gone-sideways/images/val',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')\n",
    "\n",
    "my_new_model.fit_generator(\n",
    "        train_generator, # if you don't know what argument goes first, try the hint\n",
    "        epochs = 3,\n",
    "        steps_per_epoch=19,\n",
    "        validation_data=validation_generator)\n",
    "\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Did Data Augmentation Help?\n",
    "How could you test whether data augmentation improved your model accuracy?\n",
    "\n",
    "Solution: Create train_generator usng data_generator_no_aug but don't change other arguments to train_generator.\n",
    "\n",
    "Run the model and see the resuling accuracy. Compare this to the accuracy you got when train_generator used augmentation.\n",
    "\n",
    "Our validation dataset is very small, so there's a little bit of luck or randomness in the exact score from any model run. Validation scores will be more reliable as you start using larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "You've seen how to build a model from scratch to identify handwritten digits.  You'll now build a model to identify different types of clothing.  To make models that train quickly, we'll work with very small (low-resolution) images. \n",
    "\n",
    "As an example, your model will take an images like this and identify it as a shoe:\n",
    "\n",
    "![Imgur](https://i.imgur.com/GyXOnSB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This code is supplied, and you don't need to change it. Just run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:,1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"../input/fashionmnist/fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "x, y = prep_data(fashion_data)\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_7 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Start the model\n",
    "Create a `Sequential` model called `fashion_model`. Don't add layers yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "# Your Code Here\n",
    "fashion_model = Sequential()\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Add the first layer\n",
    "\n",
    "Add the first `Conv2D` layer to `fashion_model`. It should have 12 filters, a kernel_size of 3 and the `relu` activation function. The first layer always requires that you specify the `input_shape`.  We have saved the number of rows and columns to the variables `img_rows` and `img_cols` respectively, so the input shape in this case is `(img_rows, img_cols, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "fashion_model.add(Conv2D(12,kernel_size=(3,3),activation='relu',input_shape=(img_rows, img_cols, 1)))\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Add the remaining layers\n",
    "\n",
    "1. Add 2 more convolutional (`Conv2D layers`) with 20 filters each, 'relu' activation, and a kernel size of 3. Follow that with a `Flatten` layer, and then a `Dense` layer with 100 neurons. \n",
    "2. Add your prediction layer to `fashion_model`.  This is a `Dense` layer.  We alrady have a variable called `num_classes`.  Use this variable when specifying the number of nodes in this layer. The activation should be `softmax` (or you will have problems later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "fashion_model.add(Conv2D(20,kernel_size=(3,3),activation='relu')) #convolution\n",
    "fashion_model.add(Conv2D(20,kernel_size=(3,3),activation='relu'))\n",
    "fashion_model.add(Flatten())                                   #flatten\n",
    "\n",
    "fashion_model.add(Dense(100,activation='relu'))            #Dense layer\n",
    "fashion_model.add(Dense(num_classes,activation='softmax')) #prediction layer\n",
    "\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Compile Your Model\n",
    "Compile fashion_model with the `compile` method.  Specify the following arguments:\n",
    "1. `loss = \"categorical_crossentropy\"`\n",
    "2. `optimizer = 'adam'`\n",
    "3. `metrics = ['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to compile the model in this cell\n",
    "fashion_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Fit The Model\n",
    "Run the command `fashion_model.fit`. The arguments you will use are\n",
    "1. The data used to fit the model. First comes the data holding the images, and second is the data with the class labels to be predicted. Look at the first code cell (which was supplied to you) where we called `prep_data` to find the variable names for these.\n",
    "2. `batch_size = 100`\n",
    "3. `epochs = 4`\n",
    "4. `validation_split = 0.2` -> 80% for training and 20% for validation\n",
    "\n",
    "When you run this command, you can watch your model start improving.  You will see validation accuracies after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to fit the model here\n",
    "fashion_model.fit(x,y, batch_size=100, epochs=4, validation_split=0.2)\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create A New Model\n",
    "\n",
    "Create a new model called `second_fashion_model` in the cell below.  Make some changes so it is different than `fashion_model` that you've trained above. The change could be using a different number of layers, different number of convolutions in the layers, etc.\n",
    "\n",
    "Define the model, compile it and fit it in the cell below.  See how it's validation score compares to that of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below\n",
    "second_fashion_model = Sequential()\n",
    "\n",
    "# first layer\n",
    "second_fashion_model.add(Conv2D(10, kernel_size=(3,3), activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "#Three convolutions\n",
    "second_fashion_model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "second_fashion_model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "second_fashion_model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "#Flatten\n",
    "second_fashion_model.add(Flatten())\n",
    "\n",
    "#Dense layer\n",
    "second_fashion_model.add(Dense(100,  activation='relu'))\n",
    "\n",
    "#Prediction layer\n",
    "second_fashion_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "second_fashion_model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#Fit the model\n",
    "second_fashion_model.fit(x,y,batch_size=100, epochs=4, validation_split=0.2)\n",
    "q_6.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout and Strides for Larger Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a01513088ea3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Set up code checking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_8 import *\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:,1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"../input/fashionmnist/fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "x, y = prep_data(fashion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Increasing Stride Size in A Layer\n",
    "Below is a model without strides (or more accurately, with a stride length of 1)\n",
    "\n",
    "Run it. Notice it's accuracy and how long it takes per epoch. Then you will change the stride length in one of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "batch_size = 16\n",
    "fashion_model_1 = Sequential()\n",
    "fashion_model_1.add(Conv2D(16, kernel_size=(3, 3),                     #First Conv. layer\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "fashion_model_1.add(Conv2D(16, (3, 3), activation='relu', strides=2))  #Second Conv. layer with a Stride = 2\n",
    "fashion_model_1.add(Flatten())                                         #Flat layer\n",
    "fashion_model_1.add(Dense(128, activation='relu'))                     #Dense layer\n",
    "fashion_model_1.add(Dense(num_classes, activation='softmax'))          #Prediction layer\n",
    "\n",
    "fashion_model_1.compile(loss=keras.losses.categorical_crossentropy,    #Compile the model\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fashion_model_1.fit(x, y,                                              #Fit the model\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_split = 0.2)\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My new model with Dropout and Strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "batch_size = 16\n",
    "new_model = Sequential()\n",
    "\n",
    "#first layer\n",
    "new_model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "#Dropout\n",
    "new_model.add(Dropout(0.5))\n",
    "\n",
    "#Three layers with stride=2\n",
    "new_model.add(Conv2D(10, kernel_size=(3,3), activation='relu', strides=2))\n",
    "#Dropout\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Conv2D(10, kernel_size=(3,3), activation='relu', strides=2))\n",
    "#Dropout\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Conv2D(10, kernel_size=(3,3), activation='relu', strides=2))\n",
    "#Dropout\n",
    "new_model.add(Dropout(0.5))\n",
    "\n",
    "#Flaten\n",
    "new_model.add(Flatten())\n",
    "\n",
    "#Dense layer\n",
    "new_model.add(Dense(128, activation='relu'))\n",
    "\n",
    "#Prediction layer\n",
    "new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "new_model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#Fit the model\n",
    "\n",
    "new_model.fit(x,y, batch_size=batch_size, epochs=3, validation_split=0.2)\n",
    "q_1.check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
