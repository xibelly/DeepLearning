{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input layers.\n",
    "The first step in creating a neural network model is to define the Input layer. This layer takes in raw data, usually in the form of numpy arrays. The shape of the Input layer defines how many variables your neural network will use. For example, if the input data has 10 columns, you define an Input layer with a shape of (10,).\n",
    "\n",
    "In this case, you are only using one input in your network.\n",
    "\n",
    "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the Keras Cheat Sheet and keep it handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import Input from keras.layers\n",
    "from keras.layers import Input\n",
    "\n",
    "# Create an input layer of shape 1\n",
    "input_tensor = Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense layers\n",
    "Once you have an Input layer, the next step is to add a Dense layer.\n",
    "\n",
    "Dense layers learn a weight matrix, where the first dimension of the matrix is the dimension of the input data, and the second dimension is the dimension of the output data. Recall that your Input layer has a shape of 1. In this case, your output layer will also have a shape of 1. This means that the Dense layer will learn a 1x1 weight matrix.\n",
    "\n",
    "In this exercise, you will add a dense layer to your model, after the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Input layer\n",
    "input_tensor = Input(shape=(1,))\n",
    "\n",
    "# Dense layer\n",
    "output_layer = Dense(1,)\n",
    "\n",
    "# Connect the dense layer to the input_tensor\n",
    "output_tensor = output_layer(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output layers\n",
    "Output layers are simply Dense layers! Output layers are used to reduce the dimension of the inputs to the dimension of the outputs. You'll learn more about output dimensions in chapter 4, but for now, you'll always use a single output in your neural networks, which is equivalent to Dense(1) or a dense layer with a single unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load layers\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Input layer\n",
    "input_tensor = Input(shape=(1,))\n",
    "\n",
    "# Create a dense layer and connect the dense layer to the input_tensor in one step\n",
    "# Note that we did this in 2 steps in the previous exercise, but are doing it in one step now\n",
    "output_tensor = Dense(1,)(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model\n",
    "Once you've defined an input layer and an output layer, you can build a Keras model. The model object is how you tell Keras where the model starts and stops: where data comes in and where predictions come out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/dense/output layers\n",
    "from keras.layers import Input, Dense\n",
    "input_tensor = Input(shape=(1,))\n",
    "output_tensor = Dense(1)(input_tensor)\n",
    "\n",
    "# Build the model\n",
    "from keras.models import Model\n",
    "model = Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile a model\n",
    "The final step in creating a model is compiling it. Now that you've created a model, you have to compile it before you can fit it to data. This finalizes your model, freezes all its settings, and prepares it to meet some data!\n",
    "\n",
    "During compilation, you specify the optimizer to use for fitting the model to the data, and a loss function. 'adam' is a good default optimizer to use, and will generally work well. Loss function depends on the problem at hand. Mean squared error is a common loss function and will optimize for predicting the mean, as is done in least squares regression.\n",
    "\n",
    "Mean absolute error optimizes for the median and is used in quantile regression. For this dataset, 'mean_absolute_error' works pretty well, so use it as your loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a model\n",
    "Now that you've compiled the model, take a look a the result of your hard work! You can do this by looking at the model summary, as well as its plot.\n",
    "\n",
    "The summary will tell you the names of the layers, as well as how many units they have and how many parameters are in the model.\n",
    "\n",
    "The plot will show how the layers connect to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "# Plot the model\n",
    "plot_model(model, to_file='model.png')\n",
    "\n",
    "# Display the image\n",
    "data = plt.imread('model.png')\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model to the tournament basketball data\n",
    "Now that the model is compiled, you are ready to fit it to some data!\n",
    "\n",
    "In this exercise, you'll use a dataset of scores from US College Basketball tournament games. Each row of the dataset has the team ids: team_1 and team_2, as integers. It also has the seed difference between the teams (seeds are assigned by the tournament committee and represent a ranking of how strong the teams are) and the score difference of the game (e.g. if team_1 wins by 5 points, the score difference is 5).\n",
    "\n",
    "To fit the model, you provide a matrix of X variables (in this case one column: the seed difference) and a matrix of Y variables (in this case one column: the score difference).\n",
    "\n",
    "The games_tourney DataFrame along with the compiled model object is available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the model\n",
    "model.fit(games_tourney_train.seed_diff, games_tourney_train.score_diff,\n",
    "          epochs=1,\n",
    "          batch_size=128,\n",
    "          validation_split=0.1,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on a test set\n",
    "After fitting the model, you can evaluate it on new data. You will give the model a new X matrix (also called test data), allow it to make predictions, and then compare to the known y variable (also called target data).\n",
    "\n",
    "In this case, you'll use data from the post-season tournament to evaluate your model. The tournament games happen after the regular season games you used to train our model, and are therefore a good evaluation of how well your model performs out-of-sample.\n",
    "\n",
    "The games_tourney_test DataFrame along with the fitted model object is available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the X variable from the test data\n",
    "X_test = games_tourney_test.seed_diff\n",
    "\n",
    "# Load the y variable from the test data\n",
    "y_test = games_tourney_test.score_diff\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(model.evaluate(X_test, y_test, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define team lookup.\n",
    "\n",
    "Shared layers allow a model to use the same weight matrix for multiple steps. In this exercise, you will build a \"team strength\" layer that represents each team by a single number. You will use this number for both teams in the model. The model will learn a number for each team that works well both when the team is team_1 and when the team is team_2 in the input data.\n",
    "\n",
    "The games_season DataFrame is available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from numpy import unique\n",
    "\n",
    "# Count the unique number of teams\n",
    "n_teams = unique(games_season.team_1).shape[0]\n",
    "\n",
    "# Create an embedding layer\n",
    "team_lookup = Embedding(input_dim=n_teams,\n",
    "                        output_dim=1,\n",
    "                        input_length=1,\n",
    "                        name='Team-Strength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define team model\n",
    "The team strength lookup has three components: an input, an embedding layer, and a flatten layer that creates the output.\n",
    "\n",
    "If you wrap these three layers in a model with an input and output, you can re-use that stack of three layers at multiple places.\n",
    "\n",
    "Note again that the weights for all three layers will be shared everywhere we use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.layers import Input, Embedding, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# Create an input layer for the team ID\n",
    "teamid_in = Input(shape=(1,))\n",
    "\n",
    "# Lookup the input in the team strength embedding layer\n",
    "strength_lookup = team_lookup(teamid_in)\n",
    "\n",
    "# Flatten the output\n",
    "strength_lookup_flat = Flatten()(strength_lookup)\n",
    "\n",
    "# Combine the operations into a single, re-usable model\n",
    "team_strength_model = Model(teamid_in, strength_lookup_flat, name='Team-Strength-Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
